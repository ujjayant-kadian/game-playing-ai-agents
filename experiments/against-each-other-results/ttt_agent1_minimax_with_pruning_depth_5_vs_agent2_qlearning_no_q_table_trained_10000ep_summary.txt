===== Experiment Results =====
Game: ttt

Agent 1 (Player 1): minimax
  Max Depth: 5
  Alpha-Beta Pruning: Enabled

Agent 2 (Player 2): qlearning
  Q-Table: Trained for 10000 episodes, saved to models/agent2-qtable_20250405_025959.pkl

Games Played: 10
Agent 1 Wins: 0 (0.0%)
Agent 2 Wins: 0 (0.0%)
Draws: 10 (100.0%)

===== Detailed Game Metrics =====

Agent 1 Metrics:
Total Moves: 50
Average Moves Per Game: 5.00
Min/Max Moves in a Game: 5/5
Total Time: 0.54 seconds
Average Time Per Move: 0.0109 seconds
Min/Max Time for a Move: 0.0000/0.0509 seconds
Total States Explored: 35568
Average States Explored Per Game: 3557
Min/Max States Explored in a Game: 3377/3840

Agent 2 Metrics:
Total Moves: 40
Average Moves Per Game: 4.00
Min/Max Moves in a Game: 4/4
Total Time: 0.00 seconds
Average Time Per Move: 0.0000 seconds
Min/Max Time for a Move: 0.0000/0.0001 seconds

Overall Game Information:
Average Game Duration: 0.05 seconds
Min/Max Game Duration: 0.05/0.06 seconds

===== Agent 2 Q-Learning Training Summary =====
Training Episodes: 10000
Final Evaluation Win Rate: 0.00
Q-table size: 660 states
Q-table memory usage: 777.11 KB
